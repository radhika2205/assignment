# -*- coding: utf-8 -*-
"""project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/tirthka/project.0508a213-114b-4e47-aae1-4917acb9cc83.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20260206/auto/storage/goog4_request%26X-Goog-Date%3D20260206T171515Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4de45be04ac71cd100c1e6630ec0499beee1aa7728f26e3558f8923094a5643a10e214683850a39251849ca99dd266876300e0282280f443959117800c905fdf734884bbfc66a33c1efd284d8ad453d2025d6fdc89669786c0036c897a6541c9300423247b4a1640b73bea77c55b714d52f798804ab6fc3e14dfa1456d212c6654bfa2a488b27aead475001ba333b5cd5957aa8acea0c7259b869d216de70a5ae9f722c7c3ffc39f056ccfc06d3a3e702940bb0da37d4f543743cf1df08f19a016178435572d0dfe8698a0a08c822845e1cda60487b2c3339a300dea1a5515f93fdbd43a2c4c3508f1f7dd475d13f460e9e568ba14e44369ad1f2ca8717f53c7
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
kundanbedmutha_transportation_and_accident_prediction_dataset_path = kagglehub.dataset_download('kundanbedmutha/transportation-and-accident-prediction-dataset')

print('Data source import complete.')

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

data = pd.read_csv("/kaggle/input/transportation-and-accident-prediction-dataset/Synthetic_Transportation_Dataset_Expanded_v2.csv")

data

data.info()

data = data.drop(['Record_ID','Timestamp','Road_ID','Latitude','Longitude'], axis=1)

"""# *encoding*"""

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

obj_cols = data.select_dtypes(include='object').columns

for col in obj_cols:
        data[col] = le.fit_transform(data[col])

data.info()

data.isnull().sum()

data.duplicated()

"""# *model 1 asscident severity prediction*"""

x = data.drop(['Accident_Severity'],axis=1)
y = data['Accident_Severity']

x

y

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.20,random_state=42)

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()

model.fit(x_train,y_train)

accuracy = model.score(x_test, y_test)

print("Accuracy:", accuracy)

import pickle

pickle.dump(model,open('accuracy_sevirity.pkl',"wb"))

"""# *model 2 Alert generated prediction*"""

x2 = data.drop('Alert_Generated', axis=1)
y2 = data['Alert_Generated']

from sklearn.model_selection import train_test_split

x_train2,x_test2,y_train2,y_test2 = train_test_split(x2,y2,test_size=0.20,random_state=42)

from sklearn.ensemble import RandomForestClassifier

model2 = RandomForestClassifier()

model2.fit(x_train2,y_train2)

accuracy = model2.score(x_test2, y_test2)

print("Accuracy:", accuracy)

import pickle

pickle.dump(model2,open("aelert_generated.pkl","wb"))





